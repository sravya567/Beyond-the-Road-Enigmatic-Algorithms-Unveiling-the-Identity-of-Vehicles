{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PC6CJHAimgMR"
      },
      "outputs": [],
      "source": [
        "import glob as gb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oIS9uKZ8uKX9",
        "outputId": "4539d2ad-aa29-4b99-bf1e-a501c497e272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-rnFBaovbm9",
        "outputId": "7a437957-92ac-4051-b874-ebb2d7b45633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6rb5Lh1vbpi",
        "outputId": "00a3fbd7-3861-4f0a-8875-b61c4d663e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKF6RBpdvhkD",
        "outputId": "eebd3578-0a3d-4769-dcfd-7352dba659c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 20] Not a directory: '/content/drive/MyDrive/datasets/vehicle.zip'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/datasets/vehicle.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDYBfv_Mv47w",
        "outputId": "ebcbc979-c95c-4e1f-bf96-dad2f839a126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/datasets/vehicle.zip\n",
            "  inflating: Dataset/Bus/Image_1.jpg  \n",
            "  inflating: Dataset/Bus/Image_10.jpg  \n",
            "  inflating: Dataset/Bus/Image_100.jpg  \n",
            "  inflating: Dataset/Bus/Image_11.jpg  \n",
            "  inflating: Dataset/Bus/Image_12.jpg  \n",
            "  inflating: Dataset/Bus/Image_13.jpg  \n",
            "  inflating: Dataset/Bus/Image_14.jpg  \n",
            "  inflating: Dataset/Bus/Image_15.jpg  \n",
            "  inflating: Dataset/Bus/Image_16.jpg  \n",
            "  inflating: Dataset/Bus/Image_17.jpg  \n",
            "  inflating: Dataset/Bus/Image_18.jpg  \n",
            "  inflating: Dataset/Bus/Image_19.jpg  \n",
            "  inflating: Dataset/Bus/Image_2.jpg  \n",
            "  inflating: Dataset/Bus/Image_20.jpg  \n",
            "  inflating: Dataset/Bus/Image_21.jpg  \n",
            "  inflating: Dataset/Bus/Image_22.jpg  \n",
            "  inflating: Dataset/Bus/Image_23.jpg  \n",
            "  inflating: Dataset/Bus/Image_24.png  \n",
            "  inflating: Dataset/Bus/Image_25.png  \n",
            "  inflating: Dataset/Bus/Image_26.jpg  \n",
            "  inflating: Dataset/Bus/Image_27.jpg  \n",
            "  inflating: Dataset/Bus/Image_28.JPG  \n",
            "  inflating: Dataset/Bus/Image_29.jpg  \n",
            "  inflating: Dataset/Bus/Image_3.JPG  \n",
            "  inflating: Dataset/Bus/Image_30.jpg  \n",
            "  inflating: Dataset/Bus/Image_31.jpg  \n",
            "  inflating: Dataset/Bus/Image_32.jpg  \n",
            "  inflating: Dataset/Bus/Image_33.JPG  \n",
            "  inflating: Dataset/Bus/Image_34.jpg  \n",
            "  inflating: Dataset/Bus/Image_35.jpg  \n",
            "  inflating: Dataset/Bus/Image_36.jpg  \n",
            "  inflating: Dataset/Bus/Image_37.jpg  \n",
            "  inflating: Dataset/Bus/Image_38.jpg  \n",
            "  inflating: Dataset/Bus/Image_39.JPG  \n",
            "  inflating: Dataset/Bus/Image_4.jpg  \n",
            "  inflating: Dataset/Bus/Image_40.jpg  \n",
            "  inflating: Dataset/Bus/Image_41.jpg  \n",
            "  inflating: Dataset/Bus/Image_42.jpg  \n",
            "  inflating: Dataset/Bus/Image_43.jpg  \n",
            "  inflating: Dataset/Bus/Image_44.jpg  \n",
            "  inflating: Dataset/Bus/Image_45.jpg  \n",
            "  inflating: Dataset/Bus/Image_46.jpg  \n",
            "  inflating: Dataset/Bus/Image_47.jpg  \n",
            "  inflating: Dataset/Bus/Image_48.JPG  \n",
            "  inflating: Dataset/Bus/Image_49.jpg  \n",
            "  inflating: Dataset/Bus/Image_5.jpg  \n",
            "  inflating: Dataset/Bus/Image_50.jpg  \n",
            "  inflating: Dataset/Bus/Image_51.jpg  \n",
            "  inflating: Dataset/Bus/Image_52.jpg  \n",
            "  inflating: Dataset/Bus/Image_53.jpg  \n",
            "  inflating: Dataset/Bus/Image_54.jpg  \n",
            "  inflating: Dataset/Bus/Image_55.jpg  \n",
            "  inflating: Dataset/Bus/Image_56.jpg  \n",
            "  inflating: Dataset/Bus/Image_57.jpg  \n",
            "  inflating: Dataset/Bus/Image_58.jpg  \n",
            "  inflating: Dataset/Bus/Image_59.jpg  \n",
            "  inflating: Dataset/Bus/Image_6.jpg  \n",
            "  inflating: Dataset/Bus/Image_60.jpg  \n",
            "  inflating: Dataset/Bus/Image_61.jpg  \n",
            "  inflating: Dataset/Bus/Image_62.jpg  \n",
            "  inflating: Dataset/Bus/Image_63.jpg  \n",
            "  inflating: Dataset/Bus/Image_64.jpg  \n",
            "  inflating: Dataset/Bus/Image_65.jpg  \n",
            "  inflating: Dataset/Bus/Image_66.JPG  \n",
            "  inflating: Dataset/Bus/Image_67.jpg  \n",
            "  inflating: Dataset/Bus/Image_68.jpg  \n",
            "  inflating: Dataset/Bus/Image_69.jpg  \n",
            "  inflating: Dataset/Bus/Image_7.jpg  \n",
            "  inflating: Dataset/Bus/Image_70.jpg  \n",
            "  inflating: Dataset/Bus/Image_71.jpg  \n",
            "  inflating: Dataset/Bus/Image_72.jpg  \n",
            "  inflating: Dataset/Bus/Image_73.jpg  \n",
            "  inflating: Dataset/Bus/Image_74.jpg  \n",
            "  inflating: Dataset/Bus/Image_75.jpg  \n",
            "  inflating: Dataset/Bus/Image_76.jpg  \n",
            "  inflating: Dataset/Bus/Image_77.jpg  \n",
            "  inflating: Dataset/Bus/Image_78.jpg  \n",
            "  inflating: Dataset/Bus/Image_79.png  \n",
            "  inflating: Dataset/Bus/Image_8.jpg  \n",
            "  inflating: Dataset/Bus/Image_80.jpg  \n",
            "  inflating: Dataset/Bus/Image_81.jpg  \n",
            "  inflating: Dataset/Bus/Image_82.jpg  \n",
            "  inflating: Dataset/Bus/Image_83.jpg  \n",
            "  inflating: Dataset/Bus/Image_84.jpg  \n",
            "  inflating: Dataset/Bus/Image_85.jpg  \n",
            "  inflating: Dataset/Bus/Image_86.jpg  \n",
            "  inflating: Dataset/Bus/Image_87.jpg  \n",
            "  inflating: Dataset/Bus/Image_88.jpg  \n",
            "  inflating: Dataset/Bus/Image_89.JPG  \n",
            "  inflating: Dataset/Bus/Image_9.jpg  \n",
            "  inflating: Dataset/Bus/Image_90.jpg  \n",
            "  inflating: Dataset/Bus/Image_91.jpg  \n",
            "  inflating: Dataset/Bus/Image_92.jpg  \n",
            "  inflating: Dataset/Bus/Image_93.jpeg  \n",
            "  inflating: Dataset/Bus/Image_94.jpg  \n",
            "  inflating: Dataset/Bus/Image_95.jpg  \n",
            "  inflating: Dataset/Bus/Image_96.jpg  \n",
            "  inflating: Dataset/Bus/Image_97.jpg  \n",
            "  inflating: Dataset/Bus/Image_98.jpg  \n",
            "  inflating: Dataset/Bus/Image_99.jpg  \n",
            "  inflating: Dataset/Car/Image_1.jpg  \n",
            "  inflating: Dataset/Car/Image_10.jpeg  \n",
            "  inflating: Dataset/Car/Image_100.jpg  \n",
            "  inflating: Dataset/Car/Image_11.jpg  \n",
            "  inflating: Dataset/Car/Image_12.jpg  \n",
            "  inflating: Dataset/Car/Image_13.jpg  \n",
            "  inflating: Dataset/Car/Image_14.JPG  \n",
            "  inflating: Dataset/Car/Image_15.jpg  \n",
            "  inflating: Dataset/Car/Image_16.jpeg  \n",
            "  inflating: Dataset/Car/Image_17.jpg  \n",
            "  inflating: Dataset/Car/Image_18.png  \n",
            "  inflating: Dataset/Car/Image_19.jpeg  \n",
            "  inflating: Dataset/Car/Image_2.jpg  \n",
            "  inflating: Dataset/Car/Image_20.jpg  \n",
            "  inflating: Dataset/Car/Image_21.jpg  \n",
            "  inflating: Dataset/Car/Image_22.jpg  \n",
            "  inflating: Dataset/Car/Image_23.jpg  \n",
            "  inflating: Dataset/Car/Image_24.jpg  \n",
            "  inflating: Dataset/Car/Image_25.jpg  \n",
            "  inflating: Dataset/Car/Image_26.jpg  \n",
            "  inflating: Dataset/Car/Image_27.jpg  \n",
            "  inflating: Dataset/Car/Image_28.jpg  \n",
            "  inflating: Dataset/Car/Image_29.jpg  \n",
            "  inflating: Dataset/Car/Image_3.jpeg  \n",
            "  inflating: Dataset/Car/Image_30.jpg  \n",
            "  inflating: Dataset/Car/Image_31.jpg  \n",
            "  inflating: Dataset/Car/Image_32.jpg  \n",
            "  inflating: Dataset/Car/Image_33.jpg  \n",
            "  inflating: Dataset/Car/Image_34.jpg  \n",
            "  inflating: Dataset/Car/Image_35.jpg  \n",
            "  inflating: Dataset/Car/Image_36.jpg  \n",
            "  inflating: Dataset/Car/Image_37.jpg  \n",
            "  inflating: Dataset/Car/Image_38.jpg  \n",
            "  inflating: Dataset/Car/Image_39.jpg  \n",
            "  inflating: Dataset/Car/Image_4.jpg  \n",
            "  inflating: Dataset/Car/Image_40.jpg  \n",
            "  inflating: Dataset/Car/Image_41.jpg  \n",
            "  inflating: Dataset/Car/Image_42.jpg  \n",
            "  inflating: Dataset/Car/Image_43.jpg  \n",
            "  inflating: Dataset/Car/Image_44.jpg  \n",
            "  inflating: Dataset/Car/Image_45.jpg  \n",
            "  inflating: Dataset/Car/Image_46.jpg  \n",
            "  inflating: Dataset/Car/Image_47.jpg  \n",
            "  inflating: Dataset/Car/Image_48.jpg  \n",
            "  inflating: Dataset/Car/Image_49.jpg  \n",
            "  inflating: Dataset/Car/Image_5.jpg  \n",
            "  inflating: Dataset/Car/Image_50.jpg  \n",
            "  inflating: Dataset/Car/Image_51.jpg  \n",
            "  inflating: Dataset/Car/Image_52.jpg  \n",
            "  inflating: Dataset/Car/Image_53.jpg  \n",
            "  inflating: Dataset/Car/Image_54.jpg  \n",
            "  inflating: Dataset/Car/Image_55.jpg  \n",
            "  inflating: Dataset/Car/Image_56.jpg  \n",
            "  inflating: Dataset/Car/Image_57.jpg  \n",
            "  inflating: Dataset/Car/Image_58.jpg  \n",
            "  inflating: Dataset/Car/Image_59.jpg  \n",
            "  inflating: Dataset/Car/Image_6.jpg  \n",
            "  inflating: Dataset/Car/Image_60.jpg  \n",
            "  inflating: Dataset/Car/Image_61.jpg  \n",
            "  inflating: Dataset/Car/Image_62.jpg  \n",
            "  inflating: Dataset/Car/Image_63.jpg  \n",
            "  inflating: Dataset/Car/Image_64.jpg  \n",
            "  inflating: Dataset/Car/Image_65.jpg  \n",
            "  inflating: Dataset/Car/Image_66.jpg  \n",
            "  inflating: Dataset/Car/Image_67.jpg  \n",
            "  inflating: Dataset/Car/Image_68.jpg  \n",
            "  inflating: Dataset/Car/Image_69.jpg  \n",
            "  inflating: Dataset/Car/Image_7.jpg  \n",
            "  inflating: Dataset/Car/Image_70.jpg  \n",
            "  inflating: Dataset/Car/Image_71.jpg  \n",
            "  inflating: Dataset/Car/Image_72.jpg  \n",
            "  inflating: Dataset/Car/Image_73.JPG  \n",
            "  inflating: Dataset/Car/Image_74.jpg  \n",
            "  inflating: Dataset/Car/Image_75.jpg  \n",
            "  inflating: Dataset/Car/Image_76.jpg  \n",
            "  inflating: Dataset/Car/Image_77.jpg  \n",
            "  inflating: Dataset/Car/Image_78.jpg  \n",
            "  inflating: Dataset/Car/Image_79.jpg  \n",
            "  inflating: Dataset/Car/Image_8.jpg  \n",
            "  inflating: Dataset/Car/Image_80.jpg  \n",
            "  inflating: Dataset/Car/Image_81.jpg  \n",
            "  inflating: Dataset/Car/Image_82.png  \n",
            "  inflating: Dataset/Car/Image_83.jpg  \n",
            "  inflating: Dataset/Car/Image_84.jpg  \n",
            "  inflating: Dataset/Car/Image_85.jpg  \n",
            "  inflating: Dataset/Car/Image_86.jpg  \n",
            "  inflating: Dataset/Car/Image_87.jpg  \n",
            "  inflating: Dataset/Car/Image_88.png  \n",
            "  inflating: Dataset/Car/Image_89.png  \n",
            "  inflating: Dataset/Car/Image_9.jpg  \n",
            "  inflating: Dataset/Car/Image_90.jpg  \n",
            "  inflating: Dataset/Car/Image_91.jpg  \n",
            "  inflating: Dataset/Car/Image_92.jpg  \n",
            "  inflating: Dataset/Car/Image_93.jpg  \n",
            "  inflating: Dataset/Car/Image_94.jpg  \n",
            "  inflating: Dataset/Car/Image_95.png  \n",
            "  inflating: Dataset/Car/Image_96.jpg  \n",
            "  inflating: Dataset/Car/Image_97.JPG  \n",
            "  inflating: Dataset/Car/Image_98.jpg  \n",
            "  inflating: Dataset/Car/Image_99.jpg  \n",
            "  inflating: Dataset/Truck/Image_1.jpg  \n",
            "  inflating: Dataset/Truck/Image_10.jpg  \n",
            "  inflating: Dataset/Truck/Image_100.jpg  \n",
            "  inflating: Dataset/Truck/Image_11.jpg  \n",
            "  inflating: Dataset/Truck/Image_12.jpg  \n",
            "  inflating: Dataset/Truck/Image_13.JPG  \n",
            "  inflating: Dataset/Truck/Image_14.jpg  \n",
            "  inflating: Dataset/Truck/Image_15.jpg  \n",
            "  inflating: Dataset/Truck/Image_16.jpg  \n",
            "  inflating: Dataset/Truck/Image_17.jpg  \n",
            "  inflating: Dataset/Truck/Image_18.jpg  \n",
            "  inflating: Dataset/Truck/Image_19.jpg  \n",
            "  inflating: Dataset/Truck/Image_2.jpg  \n",
            "  inflating: Dataset/Truck/Image_20.jpg  \n",
            "  inflating: Dataset/Truck/Image_21.jpg  \n",
            "  inflating: Dataset/Truck/Image_22.jpg  \n",
            "  inflating: Dataset/Truck/Image_23.jpg  \n",
            "  inflating: Dataset/Truck/Image_24.jpg  \n",
            "  inflating: Dataset/Truck/Image_25.jpg  \n",
            "  inflating: Dataset/Truck/Image_26.jpg  \n",
            "  inflating: Dataset/Truck/Image_27.jpg  \n",
            "  inflating: Dataset/Truck/Image_28.jpg  \n",
            "  inflating: Dataset/Truck/Image_29.JPG  \n",
            "  inflating: Dataset/Truck/Image_3.jpg  \n",
            "  inflating: Dataset/Truck/Image_30.jpg  \n",
            "  inflating: Dataset/Truck/Image_31.jpg  \n",
            "  inflating: Dataset/Truck/Image_32.jpg  \n",
            "  inflating: Dataset/Truck/Image_33.jpg  \n",
            "  inflating: Dataset/Truck/Image_34.jpg  \n",
            "  inflating: Dataset/Truck/Image_35.jpg  \n",
            "  inflating: Dataset/Truck/Image_36.jpg  \n",
            "  inflating: Dataset/Truck/Image_37.jpg  \n",
            "  inflating: Dataset/Truck/Image_38.jpg  \n",
            "  inflating: Dataset/Truck/Image_39.jpg  \n",
            "  inflating: Dataset/Truck/Image_4.jpg  \n",
            "  inflating: Dataset/Truck/Image_40.jpg  \n",
            "  inflating: Dataset/Truck/Image_41.jpg  \n",
            "  inflating: Dataset/Truck/Image_42.png  \n",
            "  inflating: Dataset/Truck/Image_43.jpg  \n",
            "  inflating: Dataset/Truck/Image_44.jpg  \n",
            "  inflating: Dataset/Truck/Image_45.jpg  \n",
            "  inflating: Dataset/Truck/Image_46.jpg  \n",
            "  inflating: Dataset/Truck/Image_47.jpg  \n",
            "  inflating: Dataset/Truck/Image_48.jpg  \n",
            "  inflating: Dataset/Truck/Image_49.JPG  \n",
            "  inflating: Dataset/Truck/Image_5.jpg  \n",
            "  inflating: Dataset/Truck/Image_50.jpg  \n",
            "  inflating: Dataset/Truck/Image_51.jpg  \n",
            "  inflating: Dataset/Truck/Image_52.jpg  \n",
            "  inflating: Dataset/Truck/Image_53.jpg  \n",
            "  inflating: Dataset/Truck/Image_54.jpg  \n",
            "  inflating: Dataset/Truck/Image_55.jpg  \n",
            "  inflating: Dataset/Truck/Image_56.jpeg  \n",
            "  inflating: Dataset/Truck/Image_57.png  \n",
            "  inflating: Dataset/Truck/Image_58.jpg  \n",
            "  inflating: Dataset/Truck/Image_59.jpg  \n",
            "  inflating: Dataset/Truck/Image_6.jpg  \n",
            "  inflating: Dataset/Truck/Image_60.png  \n",
            "  inflating: Dataset/Truck/Image_61.jpg  \n",
            "  inflating: Dataset/Truck/Image_62.jpg  \n",
            "  inflating: Dataset/Truck/Image_63.jpg  \n",
            "  inflating: Dataset/Truck/Image_64.jpg  \n",
            "  inflating: Dataset/Truck/Image_65.jpg  \n",
            "  inflating: Dataset/Truck/Image_66.jpg  \n",
            "  inflating: Dataset/Truck/Image_67.jpg  \n",
            "  inflating: Dataset/Truck/Image_68.jpg  \n",
            "  inflating: Dataset/Truck/Image_69.jpg  \n",
            "  inflating: Dataset/Truck/Image_7.jpg  \n",
            "  inflating: Dataset/Truck/Image_70.jpg  \n",
            "  inflating: Dataset/Truck/Image_71.jpg  \n",
            "  inflating: Dataset/Truck/Image_72.png  \n",
            "  inflating: Dataset/Truck/Image_73.jpg  \n",
            "  inflating: Dataset/Truck/Image_74.jpg  \n",
            "  inflating: Dataset/Truck/Image_75.jpg  \n",
            "  inflating: Dataset/Truck/Image_76.jpg  \n",
            "  inflating: Dataset/Truck/Image_77.png  \n",
            "  inflating: Dataset/Truck/Image_78.jpg  \n",
            "  inflating: Dataset/Truck/Image_79.png  \n",
            "  inflating: Dataset/Truck/Image_8.JPG  \n",
            "  inflating: Dataset/Truck/Image_80.jpg  \n",
            "  inflating: Dataset/Truck/Image_81.png  \n",
            "  inflating: Dataset/Truck/Image_82.jpg  \n",
            "  inflating: Dataset/Truck/Image_83.jpg  \n",
            "  inflating: Dataset/Truck/Image_84.jpg  \n",
            "  inflating: Dataset/Truck/Image_85.jpg  \n",
            "  inflating: Dataset/Truck/Image_86.png  \n",
            "  inflating: Dataset/Truck/Image_87.jpg  \n",
            "  inflating: Dataset/Truck/Image_88.jpg  \n",
            "  inflating: Dataset/Truck/Image_89.jpg  \n",
            "  inflating: Dataset/Truck/Image_9.jpg  \n",
            "  inflating: Dataset/Truck/Image_90.jpg  \n",
            "  inflating: Dataset/Truck/Image_91.jpg  \n",
            "  inflating: Dataset/Truck/Image_92.jpg  \n",
            "  inflating: Dataset/Truck/Image_93.jpg  \n",
            "  inflating: Dataset/Truck/Image_94.jpg  \n",
            "  inflating: Dataset/Truck/Image_95.jpg  \n",
            "  inflating: Dataset/Truck/Image_96.jpg  \n",
            "  inflating: Dataset/Truck/Image_97.jpg  \n",
            "  inflating: Dataset/Truck/Image_98.jpg  \n",
            "  inflating: Dataset/Truck/Image_99.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_1.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_10.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_100.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_11.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_12.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_13.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_14.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_15.png  \n",
            "  inflating: Dataset/motorcycle/Image_16.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_17.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_18.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_19.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_2.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_20.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_21.png  \n",
            "  inflating: Dataset/motorcycle/Image_22.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_23.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_24.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_25.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_26.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_27.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_28.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_29.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_3.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_30.png  \n",
            "  inflating: Dataset/motorcycle/Image_31.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_32.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_33.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_34.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_35.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_36.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_37.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_38.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_39.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_4.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_40.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_41.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_42.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_43.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_44.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_45.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_46.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_47.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_48.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_49.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_5.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_50.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_51.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_52.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_53.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_54.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_55.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_56.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_57.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_58.png  \n",
            "  inflating: Dataset/motorcycle/Image_59.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_6.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_60.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_61.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_62.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_63.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_64.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_65.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_66.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_67.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_68.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_69.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_7.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_70.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_71.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_72.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_73.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_74.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_75.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_76.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_77.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_78.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_79.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_8.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_80.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_81.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_82.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_83.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_84.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_85.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_86.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_87.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_88.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_89.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_9.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_90.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_91.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_92.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_93.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_94.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_95.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_96.jpeg  \n",
            "  inflating: Dataset/motorcycle/Image_97.JPG  \n",
            "  inflating: Dataset/motorcycle/Image_98.jpg  \n",
            "  inflating: Dataset/motorcycle/Image_99.jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/datasets/vehicle.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Agumentation"
      ],
      "metadata": {
        "id": "rdCWdOzHkV8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9HmWb2HduQRU"
      },
      "outputs": [],
      "source": [
        "image_height = 224\n",
        "image_weight = 224\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlH6PuwcuQWc",
        "outputId": "c4992884-a213-46f2-f37b-c52d8e932e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 files belonging to 4 classes.\n",
            "Using 320 files for training.\n"
          ]
        }
      ],
      "source": [
        "training_data = keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/Dataset',\n",
        "    batch_size = 16,\n",
        "    image_size =(224,224),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    subset ='training',\n",
        "    validation_split=0.2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf0KC4zHuQZW",
        "outputId": "7ebe75b2-8f7f-4ba2-bf64-58ce4a8faa3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 files belonging to 4 classes.\n",
            "Using 80 files for validation.\n"
          ]
        }
      ],
      "source": [
        "validation_data =keras.preprocessing.image_dataset_from_directory(\n",
        "   '/content/Dataset',\n",
        "    batch_size = 16,\n",
        "    image_size =(224,224),\n",
        "\n",
        "    shuffle = True,\n",
        "    seed =123,\n",
        "    validation_split =0.2,\n",
        "    subset ='validation'\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "vH0gOC_MXO9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LI5KvSKIwpkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7099f05a-5e0a-4e30-e935-a6a81dd8729d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(224,224,3),\n",
        "                   pooling='avg',classes=4,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37iwX8VVxdLD",
        "outputId": "9c71a666-b1e1-46aa-c580-a1dae38c384f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ],
      "source": [
        "resnet_model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.00009), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFoJcwfrx2Sw",
        "outputId": "497d4ea5-22f5-4986-fb12-d8c75b8c82a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 21s 534ms/step - loss: 0.8266 - accuracy: 0.6844 - val_loss: 0.2314 - val_accuracy: 0.9500\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 6s 209ms/step - loss: 0.1827 - accuracy: 0.9438 - val_loss: 0.2212 - val_accuracy: 0.9375\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 9s 277ms/step - loss: 0.1164 - accuracy: 0.9750 - val_loss: 0.2083 - val_accuracy: 0.9625\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 6s 209ms/step - loss: 0.0785 - accuracy: 0.9906 - val_loss: 0.1479 - val_accuracy: 0.9750\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 9s 268ms/step - loss: 0.0609 - accuracy: 0.9969 - val_loss: 0.1472 - val_accuracy: 0.9625\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 6s 212ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9625\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 8s 235ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9625\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 7s 213ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9625\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 7s 213ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9625\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 8s 223ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9625\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 7s 262ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9625\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 7s 215ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9625\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 7s 206ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9625\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 8s 279ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9625\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 6s 210ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9625\n"
          ]
        }
      ],
      "source": [
        "epochs = 15\n",
        "history = resnet_model.fit(training_data,\n",
        "                           validation_data = validation_data,\n",
        "                           epochs = epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"Bus\", \"Car\", \"Truck\", \"motorcycle\"]"
      ],
      "metadata": {
        "id": "COm_CiHAWA4o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_image_path = '/content/Dataset/Truck/Image_100.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = resnet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YdMwVzuV2Gu",
        "outputId": "fabb82a0-d87c-4b37-a205-4353324ad097"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUPSGGC6V2gj",
        "outputId": "5b1f3393-6a4d-4134-c14c-cfd4071ba9ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_image_path = '/content/Dataset/motorcycle/Image_16.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = resnet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RLWnCRnWO0Y",
        "outputId": "f22dfa79-3ed3-4a29-a34d-3db0123231bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m1XSf3hWOxB",
        "outputId": "cb6baf7e-6f7a-4ebc-d557-8475248877fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_image_path = '/content/Dataset/Car/Image_19.jpeg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = resnet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GelLY5UeWwzB",
        "outputId": "973c98f0-3c24-4bee-a98b-950a49ee482a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiUneQw0Ww2I",
        "outputId": "4f84c510-5b49-4c13-b65e-5d3fc4de2cc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_image_path = '/content/Dataset/Bus/Image_37.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = resnet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq65gbv1W8wP",
        "outputId": "4dc32a56-3106-4cc0-9b18-e8561c2ec5f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpdbD1asW8zQ",
        "outputId": "bf04b8bf-8f5e-454e-8731-d7e34b098327"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16"
      ],
      "metadata": {
        "id": "vx8FuybHXJEY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0x-UzCdmyeSs"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries, first!\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "j94pvOiE7hpg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cRM7HPpq7olx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7318ad1c-b346-452c-96b6-dab4758b9386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16_model = VGG16(\n",
        "    weights = 'imagenet',\n",
        "    include_top = False,\n",
        "    input_shape = (224,224, 3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Fr_faZSI7tsW"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rpyRzjOt7xVp"
      },
      "outputs": [],
      "source": [
        "car_classification_model = Sequential([\n",
        "    vgg16_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "grUdmxzu71MD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, Adamax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ohvfwubD745_"
      },
      "outputs": [],
      "source": [
        "car_classification_model.compile(\n",
        "    'adam',\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwcl5XfY78Ya",
        "outputId": "45723c09-38da-476b-d724-89f9cd30b203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21170884 (80.76 MB)\n",
            "Trainable params: 6456196 (24.63 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "car_classification_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TsBxE4J78AkL"
      },
      "outputs": [],
      "source": [
        "logdir = 'logs'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CsLhKuAx9p4S"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16_model = Sequential()\n",
        "\n",
        "pretrained_model = VGG16(include_top=False,\n",
        "                         input_shape=(224,224, 3),\n",
        "                         pooling='avg',\n",
        "                         classes=4,\n",
        "                         weights='imagenet')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASS59T8K9wqd",
        "outputId": "36c77249-6328-4b34-a1f1-7f9ca432fbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14979396 (57.14 MB)\n",
            "Trainable params: 264708 (1.01 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "vgg16_model.add(pretrained_model)\n",
        "\n",
        "vgg16_model.add(Flatten())\n",
        "vgg16_model.add(Dense(512, activation='relu'))\n",
        "vgg16_model.add(Dense(4, activation='softmax'))\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(lr=0.0001)\n",
        "vgg16_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYje3hXjh8tK",
        "outputId": "9fd33eed-972f-4d7a-e1d7-24f4f4f4fce5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOloPiXF-Iig",
        "outputId": "e0daff1d-c959-4880-a529-b52cabfcd081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 14s 318ms/step - loss: 4.0385 - accuracy: 0.6625 - val_loss: 0.4278 - val_accuracy: 0.9375\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 8s 307ms/step - loss: 0.5525 - accuracy: 0.9281 - val_loss: 0.2865 - val_accuracy: 0.9625\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 9s 259ms/step - loss: 0.1160 - accuracy: 0.9688 - val_loss: 0.3530 - val_accuracy: 0.9250\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 7s 216ms/step - loss: 0.0637 - accuracy: 0.9844 - val_loss: 0.1984 - val_accuracy: 0.9250\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 7s 216ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9250\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 8s 310ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9125\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 7s 221ms/step - loss: 1.3012e-04 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9125\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 8s 223ms/step - loss: 6.8284e-05 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9250\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 8s 295ms/step - loss: 5.4346e-05 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9250\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 7s 221ms/step - loss: 4.9404e-05 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9250\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 10s 309ms/step - loss: 4.5356e-05 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9250\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 7s 246ms/step - loss: 4.1783e-05 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9250\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 7s 229ms/step - loss: 3.9552e-05 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9250\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 9s 300ms/step - loss: 3.7448e-05 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9250\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 7s 215ms/step - loss: 3.5498e-05 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9250\n"
          ]
        }
      ],
      "source": [
        "epochs = 15\n",
        "history = vgg16_model.fit(training_data,\n",
        "                           validation_data = validation_data,\n",
        "                           epochs = epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test-1"
      ],
      "metadata": {
        "id": "j7btRiVQoq3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dYB1s7is8L48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ce2a13-cd51-4bc4-e2e3-8fce512a97e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ],
      "source": [
        "test_image_path = '/content/Dataset/Bus/Image_13.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = vgg16_model.predict(test_image_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ikwnBm-ezBHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29befe4b-8be5-4725-dc27-b84a6710a7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Bus\n"
          ]
        }
      ],
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test-2"
      ],
      "metadata": {
        "id": "-AKDbtpmotwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Car/Image_16.jpeg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = vgg16_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac905Er0ZKhl",
        "outputId": "813152c5-c3eb-4aa7-94e9-4526ecc36bf3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89kp0xkVZKXH",
        "outputId": "9fd33e6c-238e-484c-be98-a0947f4a0274"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test-3"
      ],
      "metadata": {
        "id": "Q57Xjhs-ovvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Truck/Image_44.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = vgg16_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xoOdci_ZKT_",
        "outputId": "1b0708f5-81b0-4efc-edf1-1cf0287f006e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYeiAS1HZKJ_",
        "outputId": "02556b15-ed3c-4721-9e58-8e7690f57ed7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Truck\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test-4"
      ],
      "metadata": {
        "id": "5ul5-fMioxof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/motorcycle/Image_15.png'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = vgg16_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCUy-_K3oU1g",
        "outputId": "e0785d16-a49f-40b5-a826-977641044d16"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmYjl-VEoUyZ",
        "outputId": "6561fb81-f628-4db9-b990-49a6f2d292db"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test-5"
      ],
      "metadata": {
        "id": "U-n8BZeBozty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/motorcycle/Image_12.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = vgg16_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VU5HWutommu",
        "outputId": "bde570a6-4b21-40b4-b0c3-8bef75cb44e6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXkTxOMyomj8",
        "outputId": "2ab4b617-58db-4097-a19b-45732d443e39"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: motorcycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inception"
      ],
      "metadata": {
        "id": "UaqZa21KpnTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "QErQt-E4q2Ah"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "etInfq1uplRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f21ec8-ff0a-49c8-ca7a-3fc191921332"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model = Sequential()\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "inception_model.add(pretrained_model)\n",
        "inception_model.add(Flatten())\n",
        "inception_model.add(Dense(512, activation='relu'))\n",
        "inception_model.add(Dense(4, activation='softmax'))\n",
        "inception_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlnIXDT3qh-w",
        "outputId": "e4c04411-a631-4b1d-c80d-a0ef80885697"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 51200)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               26214912  \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48019748 (183.18 MB)\n",
            "Trainable params: 26216964 (100.01 MB)\n",
            "Non-trainable params: 21802784 (83.17 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=0.0001)\n",
        "inception_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5YB5uilplUG",
        "outputId": "dde07960-df0b-40ef-afa8-f0b7929e07ad"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "history_inception = inception_model.fit(training_data, validation_data=validation_data, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zV4OkPEplW-",
        "outputId": "5d1b2aaf-e956-4a27-dd5c-1b3b3c5144db"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 16s 331ms/step - loss: 591.6508 - accuracy: 0.3438 - val_loss: 146.1115 - val_accuracy: 0.5125\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 7s 208ms/step - loss: 63.5924 - accuracy: 0.6344 - val_loss: 85.3511 - val_accuracy: 0.4500\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 8s 275ms/step - loss: 27.4671 - accuracy: 0.7688 - val_loss: 120.9359 - val_accuracy: 0.3875\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 11s 288ms/step - loss: 30.0293 - accuracy: 0.7594 - val_loss: 127.9735 - val_accuracy: 0.4500\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 10s 360ms/step - loss: 12.3588 - accuracy: 0.8438 - val_loss: 80.7327 - val_accuracy: 0.6125\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 7s 209ms/step - loss: 7.6017 - accuracy: 0.9156 - val_loss: 77.8885 - val_accuracy: 0.6000\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 7s 235ms/step - loss: 11.1361 - accuracy: 0.8875 - val_loss: 95.2172 - val_accuracy: 0.5250\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 11s 327ms/step - loss: 10.1525 - accuracy: 0.9031 - val_loss: 80.3782 - val_accuracy: 0.5625\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 7s 205ms/step - loss: 6.2646 - accuracy: 0.9125 - val_loss: 111.2109 - val_accuracy: 0.5000\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 7s 251ms/step - loss: 7.5788 - accuracy: 0.9187 - val_loss: 90.1356 - val_accuracy: 0.6125\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 7s 208ms/step - loss: 8.5335 - accuracy: 0.9281 - val_loss: 134.9080 - val_accuracy: 0.4750\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 8s 269ms/step - loss: 6.9000 - accuracy: 0.9406 - val_loss: 139.3467 - val_accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 6s 203ms/step - loss: 5.1274 - accuracy: 0.9469 - val_loss: 84.2264 - val_accuracy: 0.5750\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 7s 208ms/step - loss: 0.8229 - accuracy: 0.9812 - val_loss: 110.6834 - val_accuracy: 0.5500\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 8s 267ms/step - loss: 1.5934 - accuracy: 0.9750 - val_loss: 91.1292 - val_accuracy: 0.5375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Bus/Image_12.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = inception_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCmw2K9hplZu",
        "outputId": "66f156f9-6332-453a-d566-97d169d4acab"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUSresjGplcd",
        "outputId": "bacc8a60-127d-40fa-f790-356343f05d37"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Car/Image_13.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = inception_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYwJZGMlsE0-",
        "outputId": "730c875a-aef8-429f-b0dc-da6f7d9bd1b6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F18cbaPRsE3t",
        "outputId": "67a5c2d5-73f8-4ac9-85c5-c3fe4d23787b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Truck/Image_100.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = inception_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUOXD3DZsE6l",
        "outputId": "9fe9cb6a-95cc-440a-c846-d83699b0b998"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqim6kJbsE9N",
        "outputId": "190be441-90e0-4131-8187-03100d208877"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/motorcycle/Image_14.jpeg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = inception_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXJ-bzcWsFAL",
        "outputId": "29e30fc4-c15b-444a-e1d1-0c2abb3eb7f7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kGyJrb4sG5Z",
        "outputId": "e96618af-5bde-4ede-b481-ad373dc6b45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Densenet"
      ],
      "metadata": {
        "id": "BpqfIBScED5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "pretrained_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet_model = Sequential()\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "densenet_model.add(pretrained_model)\n",
        "densenet_model.add(Flatten())\n",
        "densenet_model.add(Dense(512, activation='relu'))\n",
        "densenet_model.add(Dense(4, activation='softmax'))\n",
        "densenet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAaMmr5L54db",
        "outputId": "216419ac-69ea-4ef8-ec7e-e18bb314813e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               25690624  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 2052      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32730180 (124.86 MB)\n",
            "Trainable params: 25692676 (98.01 MB)\n",
            "Non-trainable params: 7037504 (26.85 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=0.0001)\n",
        "densenet_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdWKjfm4CNjc",
        "outputId": "7e77a5a7-874d-459b-b7a5-36e4ea254db2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "history_densenet = densenet_model.fit(training_data, validation_data=validation_data, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtYNZq-8CNpR",
        "outputId": "78c28c91-6cdb-4f49-ed7a-93480e73ae86"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "20/20 [==============================] - 20s 380ms/step - loss: 123.7453 - accuracy: 0.4375 - val_loss: 10.5970 - val_accuracy: 0.6625\n",
            "Epoch 2/15\n",
            "20/20 [==============================] - 7s 216ms/step - loss: 8.8148 - accuracy: 0.7375 - val_loss: 19.3588 - val_accuracy: 0.6625\n",
            "Epoch 3/15\n",
            "20/20 [==============================] - 9s 214ms/step - loss: 3.2530 - accuracy: 0.8438 - val_loss: 8.2510 - val_accuracy: 0.7250\n",
            "Epoch 4/15\n",
            "20/20 [==============================] - 8s 275ms/step - loss: 1.6524 - accuracy: 0.9156 - val_loss: 5.8217 - val_accuracy: 0.7625\n",
            "Epoch 5/15\n",
            "20/20 [==============================] - 7s 215ms/step - loss: 1.1769 - accuracy: 0.9469 - val_loss: 12.7694 - val_accuracy: 0.6750\n",
            "Epoch 6/15\n",
            "20/20 [==============================] - 9s 328ms/step - loss: 0.9907 - accuracy: 0.9438 - val_loss: 7.2403 - val_accuracy: 0.7000\n",
            "Epoch 7/15\n",
            "20/20 [==============================] - 7s 213ms/step - loss: 0.5755 - accuracy: 0.9656 - val_loss: 5.6303 - val_accuracy: 0.8000\n",
            "Epoch 8/15\n",
            "20/20 [==============================] - 9s 336ms/step - loss: 0.5297 - accuracy: 0.9656 - val_loss: 5.1420 - val_accuracy: 0.7875\n",
            "Epoch 9/15\n",
            "20/20 [==============================] - 7s 211ms/step - loss: 0.1472 - accuracy: 0.9844 - val_loss: 8.1930 - val_accuracy: 0.6875\n",
            "Epoch 10/15\n",
            "20/20 [==============================] - 8s 241ms/step - loss: 0.2857 - accuracy: 0.9812 - val_loss: 10.1365 - val_accuracy: 0.7500\n",
            "Epoch 11/15\n",
            "20/20 [==============================] - 8s 277ms/step - loss: 0.4548 - accuracy: 0.9625 - val_loss: 15.2115 - val_accuracy: 0.6750\n",
            "Epoch 12/15\n",
            "20/20 [==============================] - 7s 216ms/step - loss: 0.3707 - accuracy: 0.9844 - val_loss: 6.6373 - val_accuracy: 0.7750\n",
            "Epoch 13/15\n",
            "20/20 [==============================] - 8s 292ms/step - loss: 1.0694 - accuracy: 0.9594 - val_loss: 19.5473 - val_accuracy: 0.6000\n",
            "Epoch 14/15\n",
            "20/20 [==============================] - 7s 212ms/step - loss: 2.3600 - accuracy: 0.9219 - val_loss: 8.1454 - val_accuracy: 0.7500\n",
            "Epoch 15/15\n",
            "20/20 [==============================] - 7s 217ms/step - loss: 4.0346 - accuracy: 0.8906 - val_loss: 25.9998 - val_accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Bus/Image_18.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = densenet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK4rJL1NCNtG",
        "outputId": "37e03533-4a4a-46c1-f2de-3895d90ca8f6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 152ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z96BWuVvDbTW",
        "outputId": "fdf23bf0-8552-4dae-8245-43e634877204"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: motorcycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Car/Image_16.jpeg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = densenet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygEfihWQDbae",
        "outputId": "8242a980-6a55-43be-89b3-e00fdf04a6a0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFd87z__Dbdu",
        "outputId": "20b5f1bd-6feb-40a8-ff9b-1743d00d61ae"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Car\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/Truck/Image_10.jpg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = densenet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ487aKhDbg2",
        "outputId": "ba33f04e-595f-4acf-dcde-7cfae4f423c9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkOmCreUDbkI",
        "outputId": "f3fe018c-578c-4f57-f287-9dfb4ec477bb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Truck\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_path = '/content/Dataset/motorcycle/Image_14.jpeg'\n",
        "test_image = keras.preprocessing.image.load_img(test_image_path, target_size=(224,224))\n",
        "test_image_array = keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "test_image_array /= 255.0\n",
        "predictions = densenet_model.predict(test_image_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVvr8nbvDbnQ",
        "outputId": "db34cf62-de2e-4774-bf11-86df7ca66483"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f'The predicted class is: {predicted_class_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pKel2gACNxa",
        "outputId": "66869f99-6daa-4ca3-a190-3b1da1badba7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: motorcycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving model"
      ],
      "metadata": {
        "id": "X0IpeXebkilk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.save('vehicle.h5')"
      ],
      "metadata": {
        "id": "ozfr9L0oD8Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3175526b-650e-41d1-ad0f-8db93e792add"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nWtWysKhoDdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}